{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import pennylane as qml\n",
    "from pennylane import numpy as np\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_nodes = 9\n",
    "\n",
    "# graphs for training\n",
    "graph_0 = [(0, 7), (1, 5), (1, 6), (1, 7), (2, 4), (2, 6), (2, 7), (3, 4), (3, 5), (3, 6), (4, 7), (5, 6), (5, 7), (6, 7), (6, 8), (7, 8)]\n",
    "graph_1 = [(0, 4), (1, 4), (1, 5), (1, 7), (2, 3), (2, 4), (2, 5), (2, 6), (2, 7), (2, 8), (3, 4), (3, 5), (4, 5), (4, 6), (4, 8), (5, 7)]\n",
    "\n",
    "## grid graph\n",
    "#graph_0 = nx.Graph([(0, 1), (0, 3), (1, 2), (1, 4), (2, 5), (3, 4), (3, 6), (4, 5), (4, 7), (5, 8), (6, 7), (7, 8)])\n",
    "#graph_1 = nx.Graph([(0, 2), (0, 7), (1, 5), (1, 6), (1, 8), (2, 5), (2, 8), (3, 4), (3, 7), (4, 6), (4, 8), (7, 8)])\n",
    "## cycle graph\n",
    "#graph_0 = nx.Graph([(0, 1), (0, 8), (1, 2), (2, 3), (3, 4), (4, 5), (5, 6), (6, 7), (7, 8)])\n",
    "#graph_1 = nx.Graph([(0, 4), (0, 5), (1, 7), (1, 8), (2, 4), (2, 6), (3, 5), (3, 8), (6, 7)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "# translate graphs into vectors \n",
    "g = nx.from_edgelist(graph_0)\n",
    "degree_centrality = nx.degree_centrality(g)\n",
    "feature_vec_1 = []\n",
    "\n",
    "for i in range(n_nodes):\n",
    "    feature_vec_1.append(degree_centrality.get(i))\n",
    "\n",
    "h = nx.from_edgelist(graph_1)\n",
    "degree_centrality = nx.degree_centrality(h)\n",
    "feature_vec_2 = []\n",
    "\n",
    "for i in range(n_nodes):\n",
    "    feature_vec_2.append(degree_centrality.get(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "# variational layer\n",
    "def layer(qubits, weights):\n",
    "    for j in range(qubits):\n",
    "        qml.RY(weights[0][j], wires=j)\n",
    "        qml.RZ(weights[1][j], wires=j)\n",
    "    for k in range(qubits):\n",
    "        qml.CZ(wires=[k, (k+1) % qubits])\n",
    "\n",
    "# inverse variational layer\n",
    "def inverse_layer(qubits, weights):\n",
    "    for i in range(qubits):\n",
    "        qml.CZ(wires= [qubits-(i+1), (qubits-i) % qubits])\n",
    "    for j in range(qubits):\n",
    "        qml.RZ(weights[1][j], wires=j)\n",
    "        qml.RY(weights[0][j], wires=j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "wires = range(n_nodes)\n",
    "dev = qml.device('default.qubit', n_nodes)\n",
    "\n",
    "# list circuit\n",
    "@qml.qnode(dev)\n",
    "def circuit(weights, feature_vec):\n",
    "    val = feature_vec\n",
    "    qml.AngleEmbedding(val, wires)\n",
    "    for _ in range(int(np.sqrt(n_nodes))):\n",
    "        layer(n_nodes, weights)\n",
    "\n",
    "    return qml.probs(wires)\n",
    "    #return [qml.expval(qml.PauliZ(w)) for w in wires]\n",
    "    #return qml.expval(qml.PauliZ(wires=[0])), qml.expval(qml.PauliZ(wires=[1]))\n",
    "\n",
    "@qml.qnode(dev)\n",
    "def inverse_circuit(weights, feature_vec1, feature_vec2):\n",
    "    val1 = feature_vec1\n",
    "    val2 = feature_vec2\n",
    "    qml.AngleEmbedding(val1, wires)\n",
    "    for _ in range(int(np.sqrt(n_nodes))):\n",
    "        layer(n_nodes, weights)\n",
    "    for _ in range(int(np.sqrt(n_nodes))):\n",
    "        inverse_layer(n_nodes, weights)\n",
    "    qml.AngleEmbedding(val2, wires)\n",
    "    return [qml.expval(qml.PauliZ(w)) for w in wires]\n",
    "    #return qml.expval(qml.PauliZ(wires=[0])), qml.expval(qml.PauliZ(wires=[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list architecture\n",
    "weights = np.repeat(np.pi, 18)\n",
    "weights = np.reshape(weights, (2, 9))\n",
    "\n",
    "a = circuit(weights, feature_vec_1)[0]\n",
    "b = circuit(weights, feature_vec_2)[0]\n",
    "\n",
    "## dot product equals 1 if equal vectors, dot product equals 0 if orthogonal vectors\n",
    "fidelity = np.dot(a,b)\n",
    "#print(qml.draw(circuit, expansion_strategy=\"device\")(weights, feature_vec_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "def costs(weights):\n",
    "    fidelity = np.dot(circuit(weights, feature_vec_1)[0], circuit(weights, feature_vec_2)[0])\n",
    "    return np.array(1- fidelity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Grad only applies to real scalar-output functions. Try jacobian, elementwise_grad or holomorphic_grad.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [273]\u001b[0m, in \u001b[0;36m<cell line: 12>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m### circuit results in tensor array size 2^9, but only need value at position 0 \u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_iterations):\n\u001b[1;32m---> 13\u001b[0m     weights_init, prev_cost \u001b[38;5;241m=\u001b[39m \u001b[43mopt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_and_cost\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcircuit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights_init\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_vec_1\u001b[49m\u001b[43m)\u001b[49m([\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m     14\u001b[0m     cost\u001b[38;5;241m.\u001b[39mappend(circuit(weights_init, feature_vec_1))\n\u001b[0;32m     15\u001b[0m     angle\u001b[38;5;241m.\u001b[39mappend(weights_init)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pennylane\\optimize\\gradient_descent.py:59\u001b[0m, in \u001b[0;36mGradientDescentOptimizer.step_and_cost\u001b[1;34m(self, objective_fn, grad_fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep_and_cost\u001b[39m(\u001b[38;5;28mself\u001b[39m, objective_fn, \u001b[38;5;241m*\u001b[39margs, grad_fn\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;124;03m\"\"\"Update trainable arguments with one step of the optimizer and return the corresponding\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;124;03m    objective function value prior to the step.\u001b[39;00m\n\u001b[0;32m     42\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;124;03m        If single arg is provided, list [array] is replaced by array.\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 59\u001b[0m     g, forward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_fn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     60\u001b[0m     new_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_grad(g, args)\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m forward \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pennylane\\optimize\\gradient_descent.py:117\u001b[0m, in \u001b[0;36mGradientDescentOptimizer.compute_grad\u001b[1;34m(objective_fn, args, kwargs, grad_fn)\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Compute gradient of the objective function at the given point and return it along with\u001b[39;00m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;124;03mthe objective function forward pass (if available).\u001b[39;00m\n\u001b[0;32m    101\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    114\u001b[0m \u001b[38;5;124;03m    will not be evaluted and instead ``None`` will be returned.\u001b[39;00m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    116\u001b[0m g \u001b[38;5;241m=\u001b[39m get_gradient(objective_fn) \u001b[38;5;28;01mif\u001b[39;00m grad_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m grad_fn\n\u001b[1;32m--> 117\u001b[0m grad \u001b[38;5;241m=\u001b[39m g(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    118\u001b[0m forward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(g, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforward\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    120\u001b[0m num_trainable_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(\u001b[38;5;28mgetattr\u001b[39m(arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires_grad\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m args)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pennylane\\_grad.py:120\u001b[0m, in \u001b[0;36mgrad.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fun(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ()\n\u001b[1;32m--> 120\u001b[0m grad_value, ans \u001b[38;5;241m=\u001b[39m grad_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward \u001b[38;5;241m=\u001b[39m ans\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m grad_value\n",
      "File \u001b[1;32mc:\\Users\\sabri\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\autograd\\wrap_util.py:20\u001b[0m, in \u001b[0;36munary_to_nary.<locals>.nary_operator.<locals>.nary_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     19\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(args[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m argnum)\n\u001b[1;32m---> 20\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m unary_operator(unary_f, x, \u001b[38;5;241m*\u001b[39mnary_op_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mnary_op_kwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pennylane\\_grad.py:141\u001b[0m, in \u001b[0;36mgrad._grad_with_forward\u001b[1;34m(fun, x)\u001b[0m\n\u001b[0;32m    138\u001b[0m vjp, ans \u001b[38;5;241m=\u001b[39m _make_vjp(fun, x)\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m vspace(ans)\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 141\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    142\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGrad only applies to real scalar-output functions. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    143\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTry jacobian, elementwise_grad or holomorphic_grad.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    144\u001b[0m     )\n\u001b[0;32m    146\u001b[0m grad_value \u001b[38;5;241m=\u001b[39m vjp(vspace(ans)\u001b[38;5;241m.\u001b[39mones())\n\u001b[0;32m    147\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m grad_value, ans\n",
      "\u001b[1;31mTypeError\u001b[0m: Grad only applies to real scalar-output functions. Try jacobian, elementwise_grad or holomorphic_grad."
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "weights_init = 0.01 * np.random.randn(2, n_nodes, requires_grad=True)\n",
    "angle = [weights_init]\n",
    "\n",
    "cost = 1 - np.dot(circuit(weights_init, feature_vec_1)[0], circuit(weights_init, feature_vec_2)[0])\n",
    "opt = qml.GradientDescentOptimizer()\n",
    "max_iterations = 100\n",
    "conv_tol = 1e-06\n",
    "\n",
    "\n",
    "### circuit results in tensor array size 2^9, but only need value at position 0 \n",
    "for n in range(max_iterations):\n",
    "    weights_init, prev_cost = opt.step_and_cost(circuit, weights_init, feature_vec_1)([0])\n",
    "    cost.append(circuit(weights_init, feature_vec_1))\n",
    "    angle.append(weights_init)\n",
    "\n",
    "    conv = np.abs(cost[-1] - prev_cost)\n",
    "    if n % 10 == 0:\n",
    "        print(f\"Step = {n},  Cost function = {cost[-1]:.8f} \")\n",
    "    if conv <= conv_tol:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sandwich_layer(qubits, weights):\n",
    "    for j in range(int(qubits)):\n",
    "        qml.RY(weights[0][j], wires=j)\n",
    "        qml.RZ(weights[1][j], wires=j)\n",
    "    for k in range(qubits):\n",
    "        qml.CZ(wires=[k, (k+1) % qubits])\n",
    "\n",
    "def inverse_sandwich_layer(qubits, weights):\n",
    "    for i in range(qubits):\n",
    "        qml.CZ(wires= [qubits-(i+1), (qubits-i) % qubits])\n",
    "    for j in range(qubits):\n",
    "        qml.RZ(weights[1][j], wires=j)\n",
    "        qml.RY(weights[0][j], wires=j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "## sandwich architecture circuit\n",
    "wires = range(int(np.sqrt(n_nodes)))\n",
    "dev = qml.device('default.qubit', wires)\n",
    "\n",
    "@qml.qnode(dev)\n",
    "def sandwich_circuit(weights, val):\n",
    "    qubits = int(np.sqrt(n_nodes))\n",
    "    for i in range(qubits):\n",
    "        qml.AngleEmbedding(val[i*qubits:(i*qubits)+qubits], wires)\n",
    "        sandwich_layer(qubits, weights)\n",
    "\n",
    "    return qml.probs(wires)\n",
    "\n",
    "\n",
    "@qml.qnode(dev)\n",
    "def inverse_sandwich_circuit(weights, feature_vec1, feature_vec2):\n",
    "    val1 = feature_vec1\n",
    "    val2 = feature_vec2\n",
    "    \n",
    "    qubits = int(np.sqrt(n_nodes))\n",
    "    \n",
    "    for _ in range(qubits):\n",
    "        qml.AngleEmbedding(val1[i*qubits:(i*qubits)+qubits], wires)\n",
    "        sandwich_layer(qubits, weights)\n",
    "\n",
    "    for _ in range(qubits):\n",
    "        inverse_sandwich_layer(qubits, weights)\n",
    "        qml.AngleEmbedding(val2[i*qubits:(i*qubits)+qubits], wires)\n",
    "\n",
    "    return [qml.expval(qml.PauliZ(w)) for w in wires]\n",
    "    #return qml.expval(qml.PauliZ(wires=[0])), qml.expval(qml.PauliZ(wires=[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: ──RX(0.12)──RY(3.14)──RZ(3.14)─╭●────╭Z──RX(0.38)──RY(3.14)──RZ(3.14)─╭●────╭Z──RX(0.75)\n",
      "1: ──RX(0.38)──RY(3.14)──RZ(3.14)─╰Z─╭●─│───RX(0.38)──RY(3.14)──RZ(3.14)─╰Z─╭●─│───RX(0.88)\n",
      "2: ──RX(0.38)──RY(3.14)──RZ(3.14)────╰Z─╰●──RX(0.50)──RY(3.14)──RZ(3.14)────╰Z─╰●──RX(0.25)\n",
      "\n",
      "───RY(3.14)──RZ(3.14)─╭●────╭Z─┤ ╭Probs\n",
      "───RY(3.14)──RZ(3.14)─╰Z─╭●─│──┤ ├Probs\n",
      "───RY(3.14)──RZ(3.14)────╰Z─╰●─┤ ╰Probs\n"
     ]
    }
   ],
   "source": [
    "# sandwich architecture\n",
    "weights = np.repeat(np.pi, 6)\n",
    "weights = np.reshape(weights, (2, 3))\n",
    "\n",
    "a = sandwich_circuit(weights, feature_vec_1)[0]\n",
    "b = sandwich_circuit(weights, feature_vec_2)[0]\n",
    "\n",
    "## dot product equals 1 if equal vectors, dot product equals 0 if orthogonal vectors\n",
    "fidelity = np.dot(a,b)\n",
    "print(qml.draw(sandwich_circuit, expansion_strategy=\"device\")(weights, feature_vec_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sandwich_costs(weights):\n",
    "    fidelity = np.dot(circuit(weights, feature_vec_1)[0], circuit(weights, feature_vec_2)[0])\n",
    "    return np.array(1- fidelity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "weights_init = 0.01 * np.random.randn(2, n_nodes, requires_grad=True)\n",
    "angle = [weights_init]\n",
    "\n",
    "cost = 1 - np.dot(sandwich_circuit(weights_init, feature_vec_1)[0], sandwich_circuit(weights_init, feature_vec_2)[0])\n",
    "opt = qml.GradientDescentOptimizer()\n",
    "max_iterations = 100\n",
    "conv_tol = 1e-06\n",
    "\n",
    "\n",
    "### circuit results in tensor array size 2^9, but only need value at position 0 \n",
    "for n in range(max_iterations):\n",
    "    weights_init, prev_cost = opt.step_and_cost(sandwich_circuit, weights_init, feature_vec_1)([0])\n",
    "    cost.append(sandwich_circuit(weights_init, feature_vec_1))\n",
    "    angle.append(weights_init)\n",
    "\n",
    "    conv = np.abs(cost[-1] - prev_cost)\n",
    "    if n % 10 == 0:\n",
    "        print(f\"Step = {n},  Cost function = {cost[-1]:.8f} \")\n",
    "    if conv <= conv_tol:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO\n",
    "### Optimierung List Circuit --> Fehlerbehebung, ich brauche nur das erste Element\n",
    "### Sandwich Circuit: Gewichte anpassen, damit nicht dreimal die gleichen drankommen\n",
    "### Sandwich Circuit: inverse_sandwich_circuit Amplitude Encoding in die richtige Reihenfolge bringen\n",
    "### Sandwich Circuit: Optimierung"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
